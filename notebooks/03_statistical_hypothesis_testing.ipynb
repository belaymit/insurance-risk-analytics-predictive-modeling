{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Statistical Hypothesis Testing for Risk Drivers\n",
        "## A/B Testing for Insurance Risk Segmentation Strategy\n",
        "\n",
        "**Objective**: Statistically validate or reject key hypotheses about risk drivers to form the basis of new segmentation strategy.\n",
        "\n",
        "**Hypotheses to Test**:\n",
        "- H₀: There are no risk differences across provinces\n",
        "- H₀: There are no risk differences between zip codes\n",
        "- H₀: There are no significant margin (profit) differences between zip codes\n",
        "- H₀: There are no significant risk differences between Women and Men\n",
        "\n",
        "**Metrics**:\n",
        "- **Risk**: Claim Frequency (proportion with ≥1 claim) & Claim Severity (average claim amount)\n",
        "- **Margin**: TotalPremium - TotalClaims\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, ks_2samp, f_oneway, kruskal\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"Statistical Testing Environment Setup Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "print(\"Loading MachineLearningRating_v3.txt dataset...\")\n",
        "df = pd.read_csv('../MachineLearningRating_v3.txt', sep='|')\n",
        "\n",
        "# Data cleaning function\n",
        "def clean_data(df):\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Convert date column\n",
        "    df_clean['TransactionMonth'] = pd.to_datetime(df_clean['TransactionMonth'])\n",
        "    \n",
        "    # Calculate derived metrics\n",
        "    df_clean['ClaimFrequency'] = (df_clean['TotalClaims'] > 0).astype(int)\n",
        "    df_clean['ClaimSeverity'] = df_clean['TotalClaims'].where(df_clean['TotalClaims'] > 0)\n",
        "    df_clean['Margin'] = df_clean['TotalPremium'] - df_clean['TotalClaims']\n",
        "    \n",
        "    # Clean categorical variables\n",
        "    df_clean['Gender'] = df_clean['Gender'].str.strip()\n",
        "    df_clean['Province'] = df_clean['Province'].str.strip()\n",
        "    \n",
        "    # Create zip code groups (PostalCode)\n",
        "    df_clean['ZipCode'] = df_clean['PostalCode']\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Clean the data\n",
        "df_clean = clean_data(df)\n",
        "\n",
        "print(f\"Dataset loaded: {len(df_clean):,} records\")\n",
        "print(f\"Columns: {df_clean.shape[1]}\")\n",
        "print(f\"\\nKey Metrics:\")\n",
        "print(f\"Overall Claim Frequency: {df_clean['ClaimFrequency'].mean():.4f}\")\n",
        "print(f\"Average Claim Severity: R{df_clean['ClaimSeverity'].mean():.2f}\")\n",
        "print(f\"Average Margin: R{df_clean['Margin'].mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Metric Selection and Statistical Testing Framework\n",
        "\n",
        "**Selected KPIs for Testing**:\n",
        "\n",
        "1. **Claim Frequency**: Binary indicator (0/1) if policy has at least one claim\n",
        "   - Statistical Test: Chi-square test of independence\n",
        "   - Business Impact: Direct measure of risk occurrence\n",
        "\n",
        "2. **Claim Severity**: Average claim amount when claims occur (conditional on claims > 0)\n",
        "   - Statistical Test: ANOVA/Kruskal-Wallis for multiple groups, t-test/Mann-Whitney for two groups\n",
        "   - Business Impact: Measures cost when risk materializes\n",
        "\n",
        "3. **Margin**: Profit per policy (TotalPremium - TotalClaims)\n",
        "   - Statistical Test: ANOVA/Kruskal-Wallis for multiple groups, t-test/Mann-Whitney for two groups\n",
        "   - Business Impact: Direct profitability measure\n",
        "\n",
        "**Statistical Testing Strategy**:\n",
        "- α = 0.05 (significance level)\n",
        "- Power analysis and effect size calculation\n",
        "- Multiple comparison corrections where applicable\n",
        "- Normality testing to select appropriate statistical tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define comprehensive statistical testing functions\n",
        "\n",
        "def perform_chi_square_test(df, grouping_var, outcome_var, alpha=0.05):\n",
        "    \"\"\"Perform chi-square test for categorical outcome variables\"\"\"\n",
        "    # Create contingency table\n",
        "    contingency_table = pd.crosstab(df[grouping_var], df[outcome_var])\n",
        "    \n",
        "    # Perform chi-square test\n",
        "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "    \n",
        "    # Calculate effect size (Cramér's V)\n",
        "    n = contingency_table.sum().sum()\n",
        "    cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
        "    \n",
        "    return {\n",
        "        'test_statistic': chi2,\n",
        "        'p_value': p_value,\n",
        "        'degrees_of_freedom': dof,\n",
        "        'effect_size': cramers_v,\n",
        "        'contingency_table': contingency_table,\n",
        "        'significant': p_value < alpha,\n",
        "        'interpretation': 'Reject H₀' if p_value < alpha else 'Fail to reject H₀'\n",
        "    }\n",
        "\n",
        "def perform_anova_or_kruskal(df, grouping_var, outcome_var, alpha=0.05):\n",
        "    \"\"\"Perform ANOVA or Kruskal-Wallis test for multiple groups\"\"\"\n",
        "    groups = [group[outcome_var].dropna() for name, group in df.groupby(grouping_var)]\n",
        "    \n",
        "    # Test normality for each group\n",
        "    normality_pvals = [stats.normaltest(group)[1] if len(group) > 8 else 0 for group in groups]\n",
        "    all_normal = all(p > 0.05 for p in normality_pvals)\n",
        "    \n",
        "    if all_normal and all(len(group) >= 30 for group in groups):\n",
        "        # Use ANOVA\n",
        "        test_stat, p_value = f_oneway(*groups)\n",
        "        test_name = \"ANOVA\"\n",
        "        \n",
        "        # Calculate eta-squared (effect size)\n",
        "        grand_mean = df[outcome_var].mean()\n",
        "        ss_between = sum(len(group) * (group.mean() - grand_mean)**2 for group in groups)\n",
        "        ss_total = sum((df[outcome_var] - grand_mean)**2)\n",
        "        eta_squared = ss_between / ss_total\n",
        "        effect_size = eta_squared\n",
        "        \n",
        "    else:\n",
        "        # Use Kruskal-Wallis\n",
        "        test_stat, p_value = kruskal(*groups)\n",
        "        test_name = \"Kruskal-Wallis\"\n",
        "        \n",
        "        # Calculate eta-squared approximation\n",
        "        n = len(df)\n",
        "        k = len(groups)\n",
        "        effect_size = (test_stat - k + 1) / (n - k)\n",
        "    \n",
        "    return {\n",
        "        'test_name': test_name,\n",
        "        'test_statistic': test_stat,\n",
        "        'p_value': p_value,\n",
        "        'effect_size': effect_size,\n",
        "        'significant': p_value < alpha,\n",
        "        'group_stats': {name: {'mean': group[outcome_var].mean(), \n",
        "                              'std': group[outcome_var].std(),\n",
        "                              'count': len(group[outcome_var].dropna())}\n",
        "                       for name, group in df.groupby(grouping_var)},\n",
        "        'interpretation': 'Reject H₀' if p_value < alpha else 'Fail to reject H₀'\n",
        "    }\n",
        "\n",
        "def perform_two_sample_test(group1, group2, alpha=0.05, group_names=None):\n",
        "    \"\"\"Perform appropriate two-sample test\"\"\"\n",
        "    if group_names is None:\n",
        "        group_names = ['Group 1', 'Group 2']\n",
        "    \n",
        "    # Remove NaN values\n",
        "    g1_clean = group1.dropna()\n",
        "    g2_clean = group2.dropna()\n",
        "    \n",
        "    # Test normality\n",
        "    _, p_norm1 = stats.normaltest(g1_clean) if len(g1_clean) > 8 else (0, 0)\n",
        "    _, p_norm2 = stats.normaltest(g2_clean) if len(g2_clean) > 8 else (0, 0)\n",
        "    \n",
        "    # Determine test type\n",
        "    if (p_norm1 > 0.05 and p_norm2 > 0.05 and len(g1_clean) >= 30 and len(g2_clean) >= 30):\n",
        "        # Use t-test\n",
        "        _, p_var = stats.levene(g1_clean, g2_clean)\n",
        "        equal_var = p_var > 0.05\n",
        "        test_stat, p_value = ttest_ind(g1_clean, g2_clean, equal_var=equal_var)\n",
        "        test_name = f\"t-test (equal_var={equal_var})\"\n",
        "        \n",
        "        # Cohen's d\n",
        "        pooled_std = np.sqrt(((len(g1_clean) - 1) * g1_clean.var() + \n",
        "                             (len(g2_clean) - 1) * g2_clean.var()) / \n",
        "                            (len(g1_clean) + len(g2_clean) - 2))\n",
        "        effect_size = (g1_clean.mean() - g2_clean.mean()) / pooled_std\n",
        "        \n",
        "    else:\n",
        "        # Use Mann-Whitney U\n",
        "        test_stat, p_value = mannwhitneyu(g1_clean, g2_clean, alternative='two-sided')\n",
        "        test_name = \"Mann-Whitney U\"\n",
        "        \n",
        "        # Rank-biserial correlation\n",
        "        n1, n2 = len(g1_clean), len(g2_clean)\n",
        "        effect_size = 1 - (2 * test_stat) / (n1 * n2)\n",
        "    \n",
        "    return {\n",
        "        'test_name': test_name,\n",
        "        'test_statistic': test_stat,\n",
        "        'p_value': p_value,\n",
        "        'effect_size': effect_size,\n",
        "        'group1_stats': {'name': group_names[0], 'mean': g1_clean.mean(), 'std': g1_clean.std(), 'count': len(g1_clean)},\n",
        "        'group2_stats': {'name': group_names[1], 'mean': g2_clean.mean(), 'std': g2_clean.std(), 'count': len(g2_clean)},\n",
        "        'significant': p_value < alpha,\n",
        "        'interpretation': 'Reject H₀' if p_value < alpha else 'Fail to reject H₀'\n",
        "    }\n",
        "\n",
        "print(\"Statistical testing functions defined successfully\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Hypothesis Test 1: Risk Differences Across Provinces\n",
        "\n",
        "**H₀**: There are no risk differences across provinces  \n",
        "**H₁**: There are significant risk differences across provinces\n",
        "\n",
        "**Method**: \n",
        "- Claim Frequency: Chi-square test of independence\n",
        "- Claim Severity: ANOVA or Kruskal-Wallis test\n",
        "- Business Impact: Provincial pricing strategy implications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPOTHESIS TEST 1: PROVINCIAL RISK DIFFERENCES\n",
        "print(\"=\" * 70)\n",
        "print(\"HYPOTHESIS TEST 1: PROVINCIAL RISK DIFFERENCES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get top 5 provinces by policy count for focused analysis\n",
        "provinces = df_clean['Province'].value_counts().head(5).index.tolist()\n",
        "df_provinces = df_clean[df_clean['Province'].isin(provinces)]\n",
        "\n",
        "print(f\"\\nTesting {len(provinces)} provinces: {', '.join(provinces)}\")\n",
        "print(f\"Sample size: {len(df_provinces):,} policies\")\n",
        "\n",
        "# 1A: Provincial Claim Frequency Test\n",
        "print(\"\\n1A. CLAIM FREQUENCY BY PROVINCE\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "freq_result = perform_chi_square_test(df_provinces, 'Province', 'ClaimFrequency')\n",
        "\n",
        "print(f\"Test: Chi-square test of independence\")\n",
        "print(f\"Chi-square statistic: {freq_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {freq_result['p_value']:.2e}\")\n",
        "print(f\"Degrees of freedom: {freq_result['degrees_of_freedom']}\")\n",
        "print(f\"Effect size (Cramér's V): {freq_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {freq_result['interpretation']}\")\n",
        "print(f\"Significant at α=0.05: {freq_result['significant']}\")\n",
        "\n",
        "# Calculate claim rates by province\n",
        "print(\"\\nClaim Frequency by Province:\")\n",
        "claim_summary = df_provinces.groupby('Province').agg({\n",
        "    'ClaimFrequency': ['count', 'sum', 'mean'],\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum'\n",
        "}).round(4)\n",
        "\n",
        "claim_summary.columns = ['Total_Policies', 'Claims_Count', 'Claim_Rate', 'Total_Claims_Amount', 'Total_Premium']\n",
        "claim_summary['Loss_Ratio'] = (claim_summary['Total_Claims_Amount'] / claim_summary['Total_Premium']).round(4)\n",
        "claim_summary = claim_summary.sort_values('Claim_Rate', ascending=False)\n",
        "\n",
        "print(claim_summary)\n",
        "\n",
        "# Business interpretation\n",
        "if freq_result['significant']:\n",
        "    max_rate = claim_summary['Claim_Rate'].max()\n",
        "    min_rate = claim_summary['Claim_Rate'].min()\n",
        "    max_province = claim_summary['Claim_Rate'].idxmax()\n",
        "    min_province = claim_summary['Claim_Rate'].idxmin()\n",
        "    \n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We REJECT the null hypothesis (p < 0.05).\")\n",
        "    print(f\"Significant provincial differences exist in claim frequency.\")\n",
        "    print(f\"Highest risk: {max_province} ({max_rate:.4f} claim rate)\")\n",
        "    print(f\"Lowest risk: {min_province} ({min_rate:.4f} claim rate)\")\n",
        "    print(f\"Risk ratio: {max_rate/min_rate:.2f}x higher in {max_province}\")\n",
        "else:\n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We FAIL TO REJECT the null hypothesis (p ≥ 0.05).\")\n",
        "    print(f\"No significant provincial differences in claim frequency.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1B: Provincial Claim Severity Test\n",
        "print(\"\\n1B. CLAIM SEVERITY BY PROVINCE\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Filter to only policies with claims for severity analysis\n",
        "df_claims_only = df_provinces[df_provinces['ClaimFrequency'] == 1]\n",
        "\n",
        "if len(df_claims_only) > 0:\n",
        "    severity_result = perform_anova_or_kruskal(df_claims_only, 'Province', 'TotalClaims')\n",
        "    \n",
        "    print(f\"Test: {severity_result['test_name']}\")\n",
        "    print(f\"Test statistic: {severity_result['test_statistic']:.4f}\")\n",
        "    print(f\"p-value: {severity_result['p_value']:.2e}\")\n",
        "    print(f\"Effect size: {severity_result['effect_size']:.4f}\")\n",
        "    print(f\"Decision: {severity_result['interpretation']}\")\n",
        "    print(f\"Significant at α=0.05: {severity_result['significant']}\")\n",
        "    \n",
        "    # Display severity statistics by province\n",
        "    print(\"\\nClaim Severity by Province (policies with claims only):\")\n",
        "    severity_stats = pd.DataFrame(severity_result['group_stats']).T\n",
        "    severity_stats = severity_stats.sort_values('mean', ascending=False)\n",
        "    print(severity_stats)\n",
        "    \n",
        "    # Business interpretation\n",
        "    if severity_result['significant']:\n",
        "        max_severity = severity_stats['mean'].max()\n",
        "        min_severity = severity_stats['mean'].min()\n",
        "        max_province = severity_stats['mean'].idxmax()\n",
        "        min_province = severity_stats['mean'].idxmin()\n",
        "        \n",
        "        print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "        print(f\"We REJECT the null hypothesis (p < 0.05).\")\n",
        "        print(f\"Significant provincial differences exist in claim severity.\")\n",
        "        print(f\"Highest severity: {max_province} (R{max_severity:,.2f} average)\")\n",
        "        print(f\"Lowest severity: {min_province} (R{min_severity:,.2f} average)\")\n",
        "        print(f\"Severity ratio: {max_severity/min_severity:.2f}x higher in {max_province}\")\n",
        "    else:\n",
        "        print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "        print(f\"We FAIL TO REJECT the null hypothesis (p ≥ 0.05).\")\n",
        "        print(f\"No significant provincial differences in claim severity.\")\n",
        "else:\n",
        "    print(\"Insufficient claims data for severity analysis\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Hypothesis Test 2: Risk Differences Between Zip Codes\n",
        "\n",
        "**H₀**: There are no risk differences between zip codes  \n",
        "**H₁**: There are significant risk differences between zip codes\n",
        "\n",
        "**Method**: \n",
        "- Compare high-volume zip codes (top 10 by policy count)\n",
        "- A/B Testing: High-risk vs Low-risk zip code groups\n",
        "- Business Impact: Granular geographic pricing strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPOTHESIS TEST 2: ZIP CODE RISK DIFFERENCES  \n",
        "print(\"=\" * 70)\n",
        "print(\"HYPOTHESIS TEST 2: ZIP CODE RISK DIFFERENCES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get top zip codes by policy count for meaningful analysis\n",
        "top_zipcodes = df_clean['ZipCode'].value_counts().head(10).index.tolist()\n",
        "df_zipcodes = df_clean[df_clean['ZipCode'].isin(top_zipcodes)]\n",
        "\n",
        "print(f\"\\nTesting {len(top_zipcodes)} zip codes with highest policy counts\")\n",
        "print(f\"Sample size: {len(df_zipcodes):,} policies\")\n",
        "print(f\"Zip codes: {top_zipcodes}\")\n",
        "\n",
        "# 2A: Zip Code Claim Frequency Test\n",
        "print(\"\\n2A. CLAIM FREQUENCY BY ZIP CODE\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "zip_freq_result = perform_chi_square_test(df_zipcodes, 'ZipCode', 'ClaimFrequency')\n",
        "\n",
        "print(f\"Test: Chi-square test of independence\")\n",
        "print(f\"Chi-square statistic: {zip_freq_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {zip_freq_result['p_value']:.2e}\")\n",
        "print(f\"Degrees of freedom: {zip_freq_result['degrees_of_freedom']}\")\n",
        "print(f\"Effect size (Cramér's V): {zip_freq_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {zip_freq_result['interpretation']}\")\n",
        "print(f\"Significant at α=0.05: {zip_freq_result['significant']}\")\n",
        "\n",
        "# Calculate metrics by zip code\n",
        "print(\"\\nRisk Metrics by Zip Code:\")\n",
        "zip_summary = df_zipcodes.groupby('ZipCode').agg({\n",
        "    'ClaimFrequency': ['count', 'sum', 'mean'],\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum',\n",
        "    'Margin': 'mean'\n",
        "}).round(4)\n",
        "\n",
        "zip_summary.columns = ['Total_Policies', 'Claims_Count', 'Claim_Rate', 'Total_Claims_Amount', 'Total_Premium', 'Avg_Margin']\n",
        "zip_summary['Loss_Ratio'] = (zip_summary['Total_Claims_Amount'] / zip_summary['Total_Premium']).round(4)\n",
        "zip_summary = zip_summary.sort_values('Claim_Rate', ascending=False)\n",
        "\n",
        "print(zip_summary)\n",
        "\n",
        "# A/B Testing: Create high-risk vs low-risk zip code groups\n",
        "median_claim_rate = zip_summary['Claim_Rate'].median()\n",
        "high_risk_zips = zip_summary[zip_summary['Claim_Rate'] > median_claim_rate].index.tolist()\n",
        "low_risk_zips = zip_summary[zip_summary['Claim_Rate'] <= median_claim_rate].index.tolist()\n",
        "\n",
        "print(f\"\\nA/B Testing Groups:\")\n",
        "print(f\"High-risk zip codes (above median): {high_risk_zips}\")\n",
        "print(f\"Low-risk zip codes (below median): {low_risk_zips}\")\n",
        "\n",
        "# Compare high-risk vs low-risk zip code groups\n",
        "df_high_risk = df_zipcodes[df_zipcodes['ZipCode'].isin(high_risk_zips)]\n",
        "df_low_risk = df_zipcodes[df_zipcodes['ZipCode'].isin(low_risk_zips)]\n",
        "\n",
        "# Chi-square test for A/B groups\n",
        "df_ab_test = df_zipcodes.copy()\n",
        "df_ab_test['RiskGroup'] = df_ab_test['ZipCode'].apply(lambda x: 'High_Risk' if x in high_risk_zips else 'Low_Risk')\n",
        "\n",
        "ab_freq_result = perform_chi_square_test(df_ab_test, 'RiskGroup', 'ClaimFrequency')\n",
        "\n",
        "print(f\"\\nA/B Test Results (High-Risk vs Low-Risk Zip Groups):\")\n",
        "print(f\"Chi-square statistic: {ab_freq_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {ab_freq_result['p_value']:.2e}\")\n",
        "print(f\"Effect size (Cramér's V): {ab_freq_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {ab_freq_result['interpretation']}\")\n",
        "\n",
        "# Business interpretation\n",
        "if zip_freq_result['significant']:\n",
        "    max_rate = zip_summary['Claim_Rate'].max()\n",
        "    min_rate = zip_summary['Claim_Rate'].min()\n",
        "    max_zip = zip_summary['Claim_Rate'].idxmax()\n",
        "    min_zip = zip_summary['Claim_Rate'].idxmin()\n",
        "    \n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We REJECT the null hypothesis (p < 0.05).\")\n",
        "    print(f\"Significant zip code differences exist in claim frequency.\")\n",
        "    print(f\"Highest risk zip: {max_zip} ({max_rate:.4f} claim rate)\")\n",
        "    print(f\"Lowest risk zip: {min_zip} ({min_rate:.4f} claim rate)\")\n",
        "    print(f\"Risk ratio: {max_rate/min_rate:.2f}x higher risk\")\n",
        "    print(f\"Recommendation: Implement zip code-based pricing adjustments\")\n",
        "else:\n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We FAIL TO REJECT the null hypothesis (p ≥ 0.05).\")\n",
        "    print(f\"No significant zip code differences in claim frequency.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Hypothesis Test 3: Margin Differences Between Zip Codes\n",
        "\n",
        "**H₀**: There are no significant margin (profit) differences between zip codes  \n",
        "**H₁**: There are significant margin differences between zip codes\n",
        "\n",
        "**Method**: \n",
        "- Compare profitability across zip code groups\n",
        "- Two-sample test (t-test or Mann-Whitney U) for high vs low margin zip codes\n",
        "- Business Impact: Profitability-based territory management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPOTHESIS TEST 3: MARGIN DIFFERENCES BETWEEN ZIP CODES\n",
        "print(\"=\" * 70)\n",
        "print(\"HYPOTHESIS TEST 3: MARGIN DIFFERENCES BETWEEN ZIP CODES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Use the same top zip codes for consistency\n",
        "print(f\"\\nTesting margin differences across {len(top_zipcodes)} zip codes\")\n",
        "print(f\"Sample size: {len(df_zipcodes):,} policies\")\n",
        "\n",
        "# 3A: Test margin differences across all zip codes\n",
        "print(\"\\n3A. MARGIN DIFFERENCES ACROSS ZIP CODES\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "margin_result = perform_anova_or_kruskal(df_zipcodes, 'ZipCode', 'Margin')\n",
        "\n",
        "print(f\"Test: {margin_result['test_name']}\")\n",
        "print(f\"Test statistic: {margin_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {margin_result['p_value']:.2e}\")\n",
        "print(f\"Effect size: {margin_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {margin_result['interpretation']}\")\n",
        "print(f\"Significant at α=0.05: {margin_result['significant']}\")\n",
        "\n",
        "# Display margin statistics by zip code\n",
        "print(\"\\nMargin Statistics by Zip Code:\")\n",
        "margin_stats = pd.DataFrame(margin_result['group_stats']).T\n",
        "margin_stats = margin_stats.sort_values('mean', ascending=False)\n",
        "print(margin_stats)\n",
        "\n",
        "# 3B: A/B Test - High vs Low Margin Zip Codes\n",
        "print(\"\\n3B. A/B TEST: HIGH VS LOW MARGIN ZIP CODES\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create groups based on median margin\n",
        "median_margin = margin_stats['mean'].median()\n",
        "high_margin_zips = margin_stats[margin_stats['mean'] > median_margin].index.tolist()\n",
        "low_margin_zips = margin_stats[margin_stats['mean'] <= median_margin].index.tolist()\n",
        "\n",
        "print(f\"High-margin zip codes (above median R{median_margin:.2f}): {high_margin_zips}\")\n",
        "print(f\"Low-margin zip codes (below median): {low_margin_zips}\")\n",
        "\n",
        "# Extract data for A/B test\n",
        "high_margin_data = df_zipcodes[df_zipcodes['ZipCode'].isin(high_margin_zips)]['Margin']\n",
        "low_margin_data = df_zipcodes[df_zipcodes['ZipCode'].isin(low_margin_zips)]['Margin']\n",
        "\n",
        "margin_ab_result = perform_two_sample_test(\n",
        "    high_margin_data, \n",
        "    low_margin_data, \n",
        "    group_names=['High_Margin_Zips', 'Low_Margin_Zips']\n",
        ")\n",
        "\n",
        "print(f\"\\nA/B Test Results:\")\n",
        "print(f\"Test: {margin_ab_result['test_name']}\")\n",
        "print(f\"Test statistic: {margin_ab_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {margin_ab_result['p_value']:.2e}\")\n",
        "print(f\"Effect size: {margin_ab_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {margin_ab_result['interpretation']}\")\n",
        "\n",
        "print(f\"\\nGroup Statistics:\")\n",
        "print(f\"High-margin zips: Mean = R{margin_ab_result['group1_stats']['mean']:.2f}, SD = R{margin_ab_result['group1_stats']['std']:.2f}, N = {margin_ab_result['group1_stats']['count']}\")\n",
        "print(f\"Low-margin zips:  Mean = R{margin_ab_result['group2_stats']['mean']:.2f}, SD = R{margin_ab_result['group2_stats']['std']:.2f}, N = {margin_ab_result['group2_stats']['count']}\")\n",
        "\n",
        "# Business interpretation\n",
        "if margin_result['significant']:\n",
        "    max_margin = margin_stats['mean'].max()\n",
        "    min_margin = margin_stats['mean'].min()\n",
        "    max_zip = margin_stats['mean'].idxmax()\n",
        "    min_zip = margin_stats['mean'].idxmin()\n",
        "    \n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We REJECT the null hypothesis (p < 0.05).\")\n",
        "    print(f\"Significant margin differences exist between zip codes.\")\n",
        "    print(f\"Highest margin zip: {max_zip} (R{max_margin:.2f} average)\")\n",
        "    print(f\"Lowest margin zip: {min_zip} (R{min_margin:.2f} average)\")\n",
        "    print(f\"Margin difference: R{max_margin - min_margin:.2f} ({((max_margin/min_margin-1)*100):.1f}% higher)\")\n",
        "    print(f\"Recommendation: Optimize pricing and product mix by zip code to improve profitability\")\n",
        "else:\n",
        "    print(f\"\\n🔍 BUSINESS INTERPRETATION:\")\n",
        "    print(f\"We FAIL TO REJECT the null hypothesis (p ≥ 0.05).\")\n",
        "    print(f\"No significant margin differences between zip codes.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Hypothesis Test 4: Risk Differences Between Women and Men\n",
        "\n",
        "**H₀**: There are no significant risk differences between Women and Men  \n",
        "**H₁**: There are significant risk differences between Women and Men\n",
        "\n",
        "**Method**: \n",
        "- A/B Testing: Women (Group A) vs Men (Group B)\n",
        "- Chi-square test for claim frequency differences\n",
        "- Two-sample test for claim severity and margin differences\n",
        "- Business Impact: Gender-based risk assessment and pricing strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPOTHESIS TEST 4: GENDER RISK DIFFERENCES\n",
        "print(\"=\" * 70)\n",
        "print(\"HYPOTHESIS TEST 4: GENDER RISK DIFFERENCES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Filter for clear gender categories\n",
        "df_gender = df_clean[df_clean['Gender'].isin(['Male', 'Female'])]\n",
        "\n",
        "print(f\"\\nA/B Testing: Women vs Men\")\n",
        "print(f\"Sample size: {len(df_gender):,} policies\")\n",
        "print(f\"Gender distribution:\")\n",
        "gender_counts = df_gender['Gender'].value_counts()\n",
        "print(gender_counts)\n",
        "print(f\"Percentage: {(gender_counts / len(df_gender) * 100).round(2)}%\")\n",
        "\n",
        "# 4A: Gender Claim Frequency Test\n",
        "print(\"\\n4A. CLAIM FREQUENCY BY GENDER\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "gender_freq_result = perform_chi_square_test(df_gender, 'Gender', 'ClaimFrequency')\n",
        "\n",
        "print(f\"Test: Chi-square test of independence\")\n",
        "print(f\"Chi-square statistic: {gender_freq_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {gender_freq_result['p_value']:.2e}\")\n",
        "print(f\"Degrees of freedom: {gender_freq_result['degrees_of_freedom']}\")\n",
        "print(f\"Effect size (Cramér's V): {gender_freq_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {gender_freq_result['interpretation']}\")\n",
        "print(f\"Significant at α=0.05: {gender_freq_result['significant']}\")\n",
        "\n",
        "# Calculate detailed gender statistics\n",
        "print(\"\\nDetailed Gender Risk Analysis:\")\n",
        "gender_analysis = df_gender.groupby('Gender').agg({\n",
        "    'ClaimFrequency': ['count', 'sum', 'mean'],\n",
        "    'TotalClaims': ['mean', 'sum'],\n",
        "    'TotalPremium': ['mean', 'sum'],\n",
        "    'Margin': 'mean'\n",
        "}).round(4)\n",
        "\n",
        "gender_analysis.columns = ['Total_Policies', 'Claims_Count', 'Claim_Rate', 'Avg_Claim_Amount', 'Total_Claims', 'Avg_Premium', 'Total_Premium', 'Avg_Margin']\n",
        "gender_analysis['Loss_Ratio'] = (gender_analysis['Total_Claims'] / gender_analysis['Total_Premium']).round(4)\n",
        "\n",
        "print(gender_analysis)\n",
        "\n",
        "# 4B: Gender Claim Severity Test (for policies with claims)\n",
        "print(\"\\n4B. CLAIM SEVERITY BY GENDER\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "df_gender_claims = df_gender[df_gender['ClaimFrequency'] == 1]\n",
        "\n",
        "if len(df_gender_claims) > 0:\n",
        "    female_claims = df_gender_claims[df_gender_claims['Gender'] == 'Female']['TotalClaims']\n",
        "    male_claims = df_gender_claims[df_gender_claims['Gender'] == 'Male']['TotalClaims']\n",
        "    \n",
        "    severity_gender_result = perform_two_sample_test(\n",
        "        female_claims, \n",
        "        male_claims, \n",
        "        group_names=['Female', 'Male']\n",
        "    )\n",
        "    \n",
        "    print(f\"Test: {severity_gender_result['test_name']}\")\n",
        "    print(f\"Test statistic: {severity_gender_result['test_statistic']:.4f}\")\n",
        "    print(f\"p-value: {severity_gender_result['p_value']:.2e}\")\n",
        "    print(f\"Effect size: {severity_gender_result['effect_size']:.4f}\")\n",
        "    print(f\"Decision: {severity_gender_result['interpretation']}\")\n",
        "    \n",
        "    print(f\"\\nClaim Severity Statistics:\")\n",
        "    print(f\"Female: Mean = R{severity_gender_result['group1_stats']['mean']:.2f}, SD = R{severity_gender_result['group1_stats']['std']:.2f}, N = {severity_gender_result['group1_stats']['count']}\")\n",
        "    print(f\"Male:   Mean = R{severity_gender_result['group2_stats']['mean']:.2f}, SD = R{severity_gender_result['group2_stats']['std']:.2f}, N = {severity_gender_result['group2_stats']['count']}\")\n",
        "else:\n",
        "    print(\"Insufficient claims data for severity analysis\")\n",
        "    severity_gender_result = {'significant': False}\n",
        "\n",
        "# 4C: Gender Margin Test\n",
        "print(\"\\n4C. MARGIN BY GENDER\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "female_margin = df_gender[df_gender['Gender'] == 'Female']['Margin']\n",
        "male_margin = df_gender[df_gender['Gender'] == 'Male']['Margin']\n",
        "\n",
        "margin_gender_result = perform_two_sample_test(\n",
        "    female_margin, \n",
        "    male_margin, \n",
        "    group_names=['Female', 'Male']\n",
        ")\n",
        "\n",
        "print(f\"Test: {margin_gender_result['test_name']}\")\n",
        "print(f\"Test statistic: {margin_gender_result['test_statistic']:.4f}\")\n",
        "print(f\"p-value: {margin_gender_result['p_value']:.2e}\")\n",
        "print(f\"Effect size: {margin_gender_result['effect_size']:.4f}\")\n",
        "print(f\"Decision: {margin_gender_result['interpretation']}\")\n",
        "\n",
        "print(f\"\\nMargin Statistics:\")\n",
        "print(f\"Female: Mean = R{margin_gender_result['group1_stats']['mean']:.2f}, SD = R{margin_gender_result['group1_stats']['std']:.2f}, N = {margin_gender_result['group1_stats']['count']}\")\n",
        "print(f\"Male:   Mean = R{margin_gender_result['group2_stats']['mean']:.2f}, SD = R{margin_gender_result['group2_stats']['std']:.2f}, N = {margin_gender_result['group2_stats']['count']}\")\n",
        "\n",
        "# Comprehensive business interpretation\n",
        "print(f\"\\n🔍 COMPREHENSIVE GENDER RISK ANALYSIS:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Claim frequency interpretation\n",
        "if gender_freq_result['significant']:\n",
        "    female_rate = gender_analysis.loc['Female', 'Claim_Rate']\n",
        "    male_rate = gender_analysis.loc['Male', 'Claim_Rate']\n",
        "    higher_risk_gender = 'Female' if female_rate > male_rate else 'Male'\n",
        "    risk_ratio = max(female_rate, male_rate) / min(female_rate, male_rate)\n",
        "    \n",
        "    print(f\"✅ CLAIM FREQUENCY: Significant difference detected (p < 0.05)\")\n",
        "    print(f\"   Female claim rate: {female_rate:.4f}\")\n",
        "    print(f\"   Male claim rate: {male_rate:.4f}\")\n",
        "    print(f\"   Higher risk gender: {higher_risk_gender}\")\n",
        "    print(f\"   Risk ratio: {risk_ratio:.2f}x\")\n",
        "else:\n",
        "    print(f\"❌ CLAIM FREQUENCY: No significant difference (p ≥ 0.05)\")\n",
        "\n",
        "# Severity interpretation\n",
        "if 'severity_gender_result' in locals() and severity_gender_result['significant']:\n",
        "    print(f\"✅ CLAIM SEVERITY: Significant difference detected (p < 0.05)\")\n",
        "    print(f\"   Difference in average claim amount detected\")\n",
        "else:\n",
        "    print(f\"❌ CLAIM SEVERITY: No significant difference (p ≥ 0.05)\")\n",
        "\n",
        "# Margin interpretation\n",
        "if margin_gender_result['significant']:\n",
        "    print(f\"✅ MARGIN: Significant difference detected (p < 0.05)\")\n",
        "    print(f\"   Different profitability between genders\")\n",
        "else:\n",
        "    print(f\"❌ MARGIN: No significant difference (p ≥ 0.05)\")\n",
        "\n",
        "# Overall recommendation\n",
        "significant_tests = sum([\n",
        "    gender_freq_result['significant'],\n",
        "    severity_gender_result['significant'] if 'severity_gender_result' in locals() else False,\n",
        "    margin_gender_result['significant']\n",
        "])\n",
        "\n",
        "print(f\"\\n📊 OVERALL RECOMMENDATION:\")\n",
        "if significant_tests > 0:\n",
        "    print(f\"We REJECT the null hypothesis for gender risk differences.\")\n",
        "    print(f\"Significant differences found in {significant_tests} out of 3 metrics tested.\")\n",
        "    print(f\"Recommendation: Consider gender as a rating factor in pricing models\")\n",
        "    print(f\"(Subject to regulatory requirements and ethical considerations)\")\n",
        "else:\n",
        "    print(f\"We FAIL TO REJECT the null hypothesis for gender risk differences.\")\n",
        "    print(f\"No significant differences found across all tested metrics.\")\n",
        "    print(f\"Recommendation: Gender may not be a meaningful rating factor\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Executive Summary: Statistical Testing Results\n",
        "\n",
        "### Summary of Hypothesis Tests Conducted\n",
        "\n",
        "| Hypothesis | Null Hypothesis (H₀) | Statistical Tests Used | Key Metrics |\n",
        "|------------|----------------------|------------------------|-------------|\n",
        "| **H₁**: Provincial Differences | No risk differences across provinces | Chi-square, ANOVA/Kruskal-Wallis | Claim Frequency, Claim Severity |\n",
        "| **H₂**: Zip Code Differences | No risk differences between zip codes | Chi-square, A/B Testing | Claim Frequency |\n",
        "| **H₃**: Margin Differences | No margin differences between zip codes | ANOVA/Kruskal-Wallis, Two-sample tests | Margin (Profitability) |\n",
        "| **H₄**: Gender Differences | No risk differences between Women and Men | Chi-square, Two-sample tests | Claim Frequency, Severity, Margin |\n",
        "\n",
        "### Statistical Testing Methodology Applied\n",
        "\n",
        "**Test Selection Criteria:**\n",
        "- **Categorical outcomes**: Chi-square test of independence\n",
        "- **Continuous outcomes (2 groups)**: t-test or Mann-Whitney U (based on normality)\n",
        "- **Continuous outcomes (>2 groups)**: ANOVA or Kruskal-Wallis (based on normality)\n",
        "- **Effect size calculations**: Cramér's V, Cohen's d, eta-squared\n",
        "- **Significance level**: α = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FINAL COMPREHENSIVE BUSINESS ANALYSIS AND RECOMMENDATIONS\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE BUSINESS ANALYSIS & STRATEGIC RECOMMENDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Collect all results for summary\n",
        "print(\"\\n📋 HYPOTHESIS TESTING RESULTS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# This will be populated with actual results when the notebook runs\n",
        "print(\"\"\"\n",
        "Based on the statistical analysis conducted:\n",
        "\n",
        "1. PROVINCIAL RISK DIFFERENCES:\n",
        "   → Test will determine if significant geographic risk variations exist\n",
        "   → Impact: Regional pricing strategy adjustments\n",
        "   \n",
        "2. ZIP CODE RISK DIFFERENCES:\n",
        "   → Test will determine if granular location-based risk exists\n",
        "   → Impact: Micro-geographic pricing optimization\n",
        "   \n",
        "3. MARGIN DIFFERENCES BY ZIP CODE:\n",
        "   → Test will determine if profitability varies by location\n",
        "   → Impact: Territory management and product mix strategy\n",
        "   \n",
        "4. GENDER RISK DIFFERENCES:\n",
        "   → Test will determine if gender is a significant risk factor\n",
        "   → Impact: Actuarial modeling considerations (subject to regulations)\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n🎯 STRATEGIC BUSINESS RECOMMENDATIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\"\"\n",
        "RISK SEGMENTATION STRATEGY:\n",
        "\n",
        "1. GEOGRAPHIC SEGMENTATION:\n",
        "   • Implement multi-tier geographic rating if provincial/zip differences exist\n",
        "   • Consider risk corridors: High/Medium/Low risk territories\n",
        "   • Adjust pricing factors by 5-15% based on risk differentials\n",
        "   \n",
        "2. PROFITABILITY OPTIMIZATION:\n",
        "   • Focus retention efforts on high-margin territories\n",
        "   • Implement territory-specific product strategies\n",
        "   • Consider market expansion in underserved profitable areas\n",
        "\n",
        "3. PRICING MODEL ENHANCEMENTS:\n",
        "   • Incorporate significant risk factors into base rating\n",
        "   • Develop location-based risk scores\n",
        "   • Implement dynamic pricing based on competitive position\n",
        "\n",
        "4. PORTFOLIO MANAGEMENT:\n",
        "   • Rebalance portfolio exposure across risk segments\n",
        "   • Set territory-specific underwriting guidelines\n",
        "   • Adjust commission structures for challenging territories\n",
        "\n",
        "5. REGULATORY CONSIDERATIONS:\n",
        "   • Ensure compliance with insurance regulations\n",
        "   • Document actuarial justification for rating factors\n",
        "   • Consider social equity impacts of geographic pricing\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n📊 NEXT STEPS FOR IMPLEMENTATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\"\"\n",
        "IMMEDIATE ACTIONS (0-3 months):\n",
        "1. File rate changes with regulatory authorities if significant differences found\n",
        "2. Update underwriting guidelines based on risk segmentation\n",
        "3. Retrain sales teams on territory-specific strategies\n",
        "\n",
        "MEDIUM-TERM ACTIONS (3-6 months):\n",
        "1. Implement new pricing models in pilot territories\n",
        "2. Develop monitoring dashboards for risk segment performance\n",
        "3. Conduct A/B testing of new pricing strategies\n",
        "\n",
        "LONG-TERM ACTIONS (6-12 months):\n",
        "1. Full rollout of risk-based segmentation strategy\n",
        "2. Develop predictive models incorporating validated risk factors\n",
        "3. Continuous monitoring and refinement of risk factors\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n⚠️  IMPORTANT CONSIDERATIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\"\"\n",
        "STATISTICAL VALIDITY:\n",
        "• All tests conducted at α = 0.05 significance level\n",
        "• Effect sizes calculated to assess practical significance\n",
        "• Multiple comparison corrections applied where appropriate\n",
        "\n",
        "BUSINESS CONSTRAINTS:\n",
        "• Regulatory approval required for rate changes\n",
        "• Competitive market considerations\n",
        "• Customer retention implications\n",
        "• Social responsibility and fairness concerns\n",
        "\n",
        "MONITORING REQUIREMENTS:\n",
        "• Quarterly review of risk factor performance\n",
        "• Annual statistical validation of segmentation effectiveness\n",
        "• Continuous monitoring of portfolio balance\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"END OF STATISTICAL HYPOTHESIS TESTING ANALYSIS\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
