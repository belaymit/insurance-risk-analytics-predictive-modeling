{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üìä Insurance Risk Analytics - Exploratory Data Analysis\n",
        "\n",
        "## Executive Summary\n",
        "This notebook performs comprehensive Exploratory Data Analysis (EDA) on insurance data to understand:\n",
        "- Overall Loss Ratio patterns across different segments\n",
        "- Distribution of financial variables and outlier detection\n",
        "- Temporal trends in claims and premiums\n",
        "- Vehicle characteristics impact on risk\n",
        "\n",
        "## Key Questions to Answer:\n",
        "1. **What is the overall Loss Ratio (TotalClaims / TotalPremium) for the portfolio? How does it vary by Province, VehicleType, and Gender?**\n",
        "2. **What are the distributions of key financial variables? Are there outliers in TotalClaims or CustomValueEstimate?**\n",
        "3. **Are there temporal trends? Did claim frequency or severity change over the 18-month period?**\n",
        "4. **Which vehicle makes/models are associated with the highest and lowest claim amounts?**\n",
        "\n",
        "---\n",
        "\n",
        "*Author: Data Science Team*  \n",
        "*Date: November 2024*  \n",
        "*Version: 1.0*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, normaltest, skew, kurtosis\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìÅ Data Loading and Initial Inspection\n",
        "\n",
        "Let's start by loading our insurance dataset and performing initial data quality checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the insurance dataset\n",
        "df = pd.read_csv('../data/raw/insurance_data.csv')\n",
        "\n",
        "print(f\"üìä Dataset Shape: {df.shape}\")\n",
        "print(f\"üìÖ Data Types: {df.dtypes.value_counts().to_dict()}\")\n",
        "print(f\"üíæ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nüîç First 5 rows of the dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nüìã Dataset Information:\")\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîç Data Quality Assessment\n",
        "\n",
        "Let's examine data quality by checking for missing values, data types, and basic statistical summaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Assessment\n",
        "print(\"üîç Missing Values Analysis:\")\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percentage\n",
        "}).sort_values('Missing Count', ascending=False)\n",
        "\n",
        "print(missing_summary[missing_summary['Missing Count'] > 0])\n",
        "\n",
        "if missing_summary['Missing Count'].sum() == 0:\n",
        "    print(\"‚úÖ No missing values found in the dataset!\")\n",
        "\n",
        "# Check for duplicate records\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nüîÑ Duplicate Records: {duplicates}\")\n",
        "\n",
        "# Data type verification\n",
        "print(\"\\nüìä Data Types Verification:\")\n",
        "for col in df.columns:\n",
        "    dtype = df[col].dtype\n",
        "    unique_count = df[col].nunique()\n",
        "    print(f\"{col:20} | {str(dtype):12} | Unique Values: {unique_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive Statistics for Numerical Variables\n",
        "print(\"üìà Descriptive Statistics for Numerical Variables:\")\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "desc_stats = df[numerical_cols].describe()\n",
        "\n",
        "# Add additional statistical measures\n",
        "additional_stats = pd.DataFrame({\n",
        "    'skewness': df[numerical_cols].skew(),\n",
        "    'kurtosis': df[numerical_cols].kurtosis(),\n",
        "    'variance': df[numerical_cols].var()\n",
        "}).round(4)\n",
        "\n",
        "# Combine descriptive statistics\n",
        "full_stats = pd.concat([desc_stats.round(2), additional_stats.T], axis=0)\n",
        "display(full_stats)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Key Question 1: Loss Ratio Analysis\n",
        "\n",
        "**What is the overall Loss Ratio (TotalClaims / TotalPremium) for the portfolio? How does it vary by Province, VehicleType, and Gender?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall Loss Ratio\n",
        "overall_loss_ratio = df['TotalClaims'].sum() / df['TotalPremium'].sum()\n",
        "print(f\"üìä Overall Portfolio Loss Ratio: {overall_loss_ratio:.4f} ({overall_loss_ratio*100:.2f}%)\")\n",
        "\n",
        "# Calculate Loss Ratio by different segments\n",
        "print(\"\\nüéØ Loss Ratio Analysis by Segments:\")\n",
        "\n",
        "# By Province\n",
        "province_loss_ratio = df.groupby('Province').agg({\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum',\n",
        "    'PolicyID': 'count'\n",
        "}).reset_index()\n",
        "province_loss_ratio['LossRatio'] = province_loss_ratio['TotalClaims'] / province_loss_ratio['TotalPremium']\n",
        "province_loss_ratio = province_loss_ratio.sort_values('LossRatio', ascending=False)\n",
        "province_loss_ratio.columns = ['Province', 'Total_Claims', 'Total_Premium', 'Policy_Count', 'Loss_Ratio']\n",
        "\n",
        "print(\"\\nüìç Loss Ratio by Province:\")\n",
        "display(province_loss_ratio.round(4))\n",
        "\n",
        "# By Vehicle Type\n",
        "vehicle_loss_ratio = df.groupby('VehicleType').agg({\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum',\n",
        "    'PolicyID': 'count'\n",
        "}).reset_index()\n",
        "vehicle_loss_ratio['LossRatio'] = vehicle_loss_ratio['TotalClaims'] / vehicle_loss_ratio['TotalPremium']\n",
        "vehicle_loss_ratio = vehicle_loss_ratio.sort_values('LossRatio', ascending=False)\n",
        "vehicle_loss_ratio.columns = ['Vehicle_Type', 'Total_Claims', 'Total_Premium', 'Policy_Count', 'Loss_Ratio']\n",
        "\n",
        "print(\"\\nüöó Loss Ratio by Vehicle Type:\")\n",
        "display(vehicle_loss_ratio.round(4))\n",
        "\n",
        "# By Gender\n",
        "gender_loss_ratio = df.groupby('Gender').agg({\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum',\n",
        "    'PolicyID': 'count'\n",
        "}).reset_index()\n",
        "gender_loss_ratio['LossRatio'] = gender_loss_ratio['TotalClaims'] / gender_loss_ratio['TotalPremium']\n",
        "gender_loss_ratio = gender_loss_ratio.sort_values('LossRatio', ascending=False)\n",
        "gender_loss_ratio.columns = ['Gender', 'Total_Claims', 'Total_Premium', 'Policy_Count', 'Loss_Ratio']\n",
        "\n",
        "print(\"\\nüë• Loss Ratio by Gender:\")\n",
        "display(gender_loss_ratio.round(4))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Key Question 2: Distribution Analysis & Outlier Detection\n",
        "\n",
        "**What are the distributions of key financial variables? Are there outliers in TotalClaims or CustomValueEstimate that could skew our analysis?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution Analysis of Key Financial Variables\n",
        "financial_vars = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate']\n",
        "\n",
        "print(\"üìà Distribution Analysis of Financial Variables:\")\n",
        "for var in financial_vars:\n",
        "    print(f\"\\n--- {var} ---\")\n",
        "    data = df[var]\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"Mean: ${data.mean():,.2f}\")\n",
        "    print(f\"Median: ${data.median():,.2f}\")\n",
        "    print(f\"Std Dev: ${data.std():,.2f}\")\n",
        "    print(f\"Skewness: {skew(data):.4f}\")\n",
        "    print(f\"Kurtosis: {kurtosis(data):.4f}\")\n",
        "    \n",
        "    # Test for normality\n",
        "    stat, p_value = normaltest(data)\n",
        "    print(f\"Normality Test (D'Agostino): p-value = {p_value:.6f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"‚ùå Data is NOT normally distributed\")\n",
        "    else:\n",
        "        print(\"‚úÖ Data appears normally distributed\")\n",
        "\n",
        "# Outlier Detection using IQR method\n",
        "print(\"\\nüéØ Outlier Detection (IQR Method):\")\n",
        "for var in financial_vars:\n",
        "    data = df[var]\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
        "    outlier_percentage = (len(outliers) / len(data)) * 100\n",
        "    \n",
        "    print(f\"\\n{var}:\")\n",
        "    print(f\"  Lower Bound: ${lower_bound:,.2f}\")\n",
        "    print(f\"  Upper Bound: ${upper_bound:,.2f}\")\n",
        "    print(f\"  Outliers: {len(outliers)} ({outlier_percentage:.2f}%)\")\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  Max Outlier: ${outliers.max():,.2f}\")\n",
        "        print(f\"  Min Outlier: ${outliers.min():,.2f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìÖ Key Question 3: Temporal Trends Analysis\n",
        "\n",
        "**Are there temporal trends? Did the claim frequency or severity change over the 18-month period?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal Analysis\n",
        "print(\"üìÖ Temporal Trends Analysis:\")\n",
        "\n",
        "# Convert TransactionDate to datetime if not already\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n",
        "df['Year_Month'] = df['TransactionDate'].dt.to_period('M')\n",
        "\n",
        "# Monthly aggregations\n",
        "monthly_stats = df.groupby('Year_Month').agg({\n",
        "    'TotalPremium': ['sum', 'mean', 'count'],\n",
        "    'TotalClaims': ['sum', 'mean'],\n",
        "    'HasClaim': ['sum', 'mean'],\n",
        "    'CustomValueEstimate': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "# Flatten column names\n",
        "monthly_stats.columns = ['_'.join(col).strip() for col in monthly_stats.columns]\n",
        "monthly_stats.reset_index(inplace=True)\n",
        "\n",
        "# Calculate additional metrics\n",
        "monthly_stats['Claim_Frequency'] = monthly_stats['HasClaim_sum'] / monthly_stats['TotalPremium_count'] * 100\n",
        "monthly_stats['Avg_Claim_Severity'] = monthly_stats['TotalClaims_sum'] / monthly_stats['HasClaim_sum']\n",
        "monthly_stats['Loss_Ratio'] = monthly_stats['TotalClaims_sum'] / monthly_stats['TotalPremium_sum']\n",
        "\n",
        "# Handle division by zero\n",
        "monthly_stats['Avg_Claim_Severity'] = monthly_stats['Avg_Claim_Severity'].fillna(0)\n",
        "monthly_stats['Loss_Ratio'] = monthly_stats['Loss_Ratio'].fillna(0)\n",
        "\n",
        "print(\"üìà Monthly Trends Summary:\")\n",
        "display(monthly_stats.round(2))\n",
        "\n",
        "# Identify trends\n",
        "print(\"\\nüîç Trend Analysis:\")\n",
        "print(f\"Claim Frequency Range: {monthly_stats['Claim_Frequency'].min():.2f}% - {monthly_stats['Claim_Frequency'].max():.2f}%\")\n",
        "print(f\"Average Claim Severity Range: ${monthly_stats['Avg_Claim_Severity'].min():,.2f} - ${monthly_stats['Avg_Claim_Severity'].max():,.2f}\")\n",
        "print(f\"Loss Ratio Range: {monthly_stats['Loss_Ratio'].min():.4f} - {monthly_stats['Loss_Ratio'].max():.4f}\")\n",
        "\n",
        "# Correlation with time (using month number as proxy)\n",
        "monthly_stats['Month_Number'] = range(1, len(monthly_stats) + 1)\n",
        "freq_correlation = monthly_stats['Claim_Frequency'].corr(monthly_stats['Month_Number'])\n",
        "severity_correlation = monthly_stats['Avg_Claim_Severity'].corr(monthly_stats['Month_Number'])\n",
        "\n",
        "print(f\"\\nüìä Correlation with Time:\")\n",
        "print(f\"Claim Frequency vs Time: {freq_correlation:.4f}\")\n",
        "print(f\"Claim Severity vs Time: {severity_correlation:.4f}\")\n",
        "\n",
        "if abs(freq_correlation) > 0.3:\n",
        "    trend_direction = \"increasing\" if freq_correlation > 0 else \"decreasing\"\n",
        "    print(f\"üî∫ Notable {trend_direction} trend in claim frequency over time\")\n",
        "if abs(severity_correlation) > 0.3:\n",
        "    trend_direction = \"increasing\" if severity_correlation > 0 else \"decreasing\"\n",
        "    print(f\"üî∫ Notable {trend_direction} trend in claim severity over time\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöó Key Question 4: Vehicle Analysis\n",
        "\n",
        "**Which vehicle makes/models are associated with the highest and lowest claim amounts?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vehicle Analysis\n",
        "print(\"üöó Vehicle Analysis - Claims by Make and Type:\")\n",
        "\n",
        "# Analysis by Vehicle Make\n",
        "vehicle_make_analysis = df.groupby('VehicleMake').agg({\n",
        "    'TotalClaims': ['sum', 'mean', 'count'],\n",
        "    'TotalPremium': ['sum', 'mean'],\n",
        "    'HasClaim': ['sum', 'mean'],\n",
        "    'CustomValueEstimate': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "vehicle_make_analysis.columns = ['_'.join(col).strip() for col in vehicle_make_analysis.columns]\n",
        "vehicle_make_analysis.reset_index(inplace=True)\n",
        "\n",
        "# Calculate additional metrics\n",
        "vehicle_make_analysis['Avg_Claim_Amount'] = vehicle_make_analysis['TotalClaims_sum'] / vehicle_make_analysis['HasClaim_sum']\n",
        "vehicle_make_analysis['Claim_Frequency_Pct'] = vehicle_make_analysis['HasClaim_mean'] * 100\n",
        "vehicle_make_analysis['Loss_Ratio'] = vehicle_make_analysis['TotalClaims_sum'] / vehicle_make_analysis['TotalPremium_sum']\n",
        "\n",
        "# Handle division by zero\n",
        "vehicle_make_analysis['Avg_Claim_Amount'] = vehicle_make_analysis['Avg_Claim_Amount'].fillna(0)\n",
        "\n",
        "# Sort by different metrics\n",
        "print(\"üìä Vehicle Makes Ranked by Average Claim Amount:\")\n",
        "top_claim_makes = vehicle_make_analysis.sort_values('Avg_Claim_Amount', ascending=False)\n",
        "display(top_claim_makes[['VehicleMake', 'TotalClaims_count', 'Avg_Claim_Amount', 'Claim_Frequency_Pct', 'Loss_Ratio']].round(2))\n",
        "\n",
        "print(\"\\nüèÜ Top 3 Highest Risk Vehicle Makes:\")\n",
        "for i, row in top_claim_makes.head(3).iterrows():\n",
        "    print(f\"{row['VehicleMake']}: Avg Claim ${row['Avg_Claim_Amount']:,.2f}, Frequency {row['Claim_Frequency_Pct']:.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ Top 3 Lowest Risk Vehicle Makes:\")\n",
        "for i, row in top_claim_makes.tail(3).iterrows():\n",
        "    if row['Avg_Claim_Amount'] > 0:  # Only include makes with actual claims\n",
        "        print(f\"{row['VehicleMake']}: Avg Claim ${row['Avg_Claim_Amount']:,.2f}, Frequency {row['Claim_Frequency_Pct']:.1f}%\")\n",
        "\n",
        "# Vehicle Type Analysis\n",
        "print(\"\\n\\nüöô Vehicle Types Analysis:\")\n",
        "vehicle_type_analysis = df.groupby('VehicleType').agg({\n",
        "    'TotalClaims': ['sum', 'mean'],\n",
        "    'HasClaim': ['sum', 'mean'],\n",
        "    'TotalPremium': 'sum',\n",
        "    'CustomValueEstimate': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "vehicle_type_analysis.columns = ['_'.join(col).strip() for col in vehicle_type_analysis.columns]\n",
        "vehicle_type_analysis.reset_index(inplace=True)\n",
        "vehicle_type_analysis['Avg_Claim_Amount'] = vehicle_type_analysis['TotalClaims_sum'] / vehicle_type_analysis['HasClaim_sum']\n",
        "vehicle_type_analysis['Claim_Frequency_Pct'] = vehicle_type_analysis['HasClaim_mean'] * 100\n",
        "vehicle_type_analysis = vehicle_type_analysis.sort_values('Avg_Claim_Amount', ascending=False)\n",
        "\n",
        "display(vehicle_type_analysis[['VehicleType', 'Avg_Claim_Amount', 'Claim_Frequency_Pct', 'CustomValueEstimate_mean']].round(2))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üé® Creative Visualizations - Key Insights\n",
        "\n",
        "**Three beautiful and insightful plots that capture the key insights from our EDA:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé® VISUALIZATION 1: Interactive Loss Ratio Heatmap by Province and Vehicle Type\n",
        "print(\"üé® Creating Visualization 1: Interactive Loss Ratio Heatmap\")\n",
        "\n",
        "# Create pivot table for heatmap\n",
        "loss_ratio_pivot = df.groupby(['Province', 'VehicleType']).agg({\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "loss_ratio_pivot['Loss_Ratio'] = loss_ratio_pivot['TotalClaims'] / loss_ratio_pivot['TotalPremium']\n",
        "heatmap_data = loss_ratio_pivot.pivot(index='Province', columns='VehicleType', values='Loss_Ratio')\n",
        "\n",
        "# Create interactive heatmap using Plotly\n",
        "fig1 = go.Figure(data=go.Heatmap(\n",
        "    z=heatmap_data.values,\n",
        "    x=heatmap_data.columns,\n",
        "    y=heatmap_data.index,\n",
        "    colorscale='RdYlBu_r',\n",
        "    colorbar=dict(title=\"Loss Ratio\"),\n",
        "    hoverongaps=False,\n",
        "    hovertemplate='Province: %{y}<br>Vehicle Type: %{x}<br>Loss Ratio: %{z:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig1.update_layout(\n",
        "    title={\n",
        "        'text': 'üî• Loss Ratio Heatmap: Risk Patterns by Province & Vehicle Type',\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'font': {'size': 18}\n",
        "    },\n",
        "    xaxis_title=\"Vehicle Type\",\n",
        "    yaxis_title=\"Province\",\n",
        "    font=dict(size=12),\n",
        "    height=600,\n",
        "    width=900\n",
        ")\n",
        "\n",
        "fig1.show()\n",
        "print(\"‚úÖ Heatmap created - Shows risk concentration patterns across geography and vehicle types\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé® VISUALIZATION 2: Multi-Dimensional Bubble Chart - Risk vs Profitability\n",
        "print(\"üé® Creating Visualization 2: Risk vs Profitability Bubble Chart\")\n",
        "\n",
        "# Prepare data for bubble chart\n",
        "bubble_data = df.groupby('VehicleMake').agg({\n",
        "    'TotalClaims': 'sum',\n",
        "    'TotalPremium': 'sum',\n",
        "    'HasClaim': 'mean',\n",
        "    'PolicyID': 'count',\n",
        "    'CustomValueEstimate': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "bubble_data['Loss_Ratio'] = bubble_data['TotalClaims'] / bubble_data['TotalPremium']\n",
        "bubble_data['Claim_Frequency'] = bubble_data['HasClaim'] * 100\n",
        "bubble_data['Portfolio_Size'] = bubble_data['PolicyID']\n",
        "\n",
        "# Create bubble chart\n",
        "fig2 = px.scatter(\n",
        "    bubble_data,\n",
        "    x='Claim_Frequency',\n",
        "    y='Loss_Ratio',\n",
        "    size='Portfolio_Size',\n",
        "    color='CustomValueEstimate',\n",
        "    hover_name='VehicleMake',\n",
        "    hover_data={\n",
        "        'Claim_Frequency': ':.2f',\n",
        "        'Loss_Ratio': ':.4f',\n",
        "        'Portfolio_Size': ':,',\n",
        "        'CustomValueEstimate': ':,.0f'\n",
        "    },\n",
        "    labels={\n",
        "        'Claim_Frequency': 'Claim Frequency (%)',\n",
        "        'Loss_Ratio': 'Loss Ratio',\n",
        "        'Portfolio_Size': 'Number of Policies',\n",
        "        'CustomValueEstimate': 'Avg Vehicle Value ($)'\n",
        "    },\n",
        "    title='üíº Risk vs Profitability: Vehicle Make Analysis<br><sub>Size = Portfolio Size, Color = Average Vehicle Value</sub>',\n",
        "    color_continuous_scale='Viridis'\n",
        ")\n",
        "\n",
        "# Add quadrant lines\n",
        "avg_freq = bubble_data['Claim_Frequency'].mean()\n",
        "avg_loss = bubble_data['Loss_Ratio'].mean()\n",
        "\n",
        "fig2.add_hline(y=avg_loss, line_dash=\"dash\", line_color=\"red\", \n",
        "               annotation_text=\"Average Loss Ratio\", annotation_position=\"right\")\n",
        "fig2.add_vline(x=avg_freq, line_dash=\"dash\", line_color=\"red\",\n",
        "               annotation_text=\"Average Claim Frequency\", annotation_position=\"top\")\n",
        "\n",
        "fig2.update_layout(\n",
        "    width=1000,\n",
        "    height=700,\n",
        "    title_font_size=16,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "fig2.show()\n",
        "print(\"‚úÖ Bubble chart created - Reveals risk-profitability relationships and portfolio concentration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé® VISUALIZATION 3: Temporal Evolution Dashboard with Multiple Metrics\n",
        "print(\"üé® Creating Visualization 3: Temporal Evolution Dashboard\")\n",
        "\n",
        "# Create subplots\n",
        "fig3 = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Monthly Claim Frequency Trend', 'Monthly Loss Ratio Evolution',\n",
        "                   'Premium vs Claims Volume', 'Risk Score by Vehicle Age'),\n",
        "    specs=[[{\"secondary_y\": True}, {\"secondary_y\": False}],\n",
        "           [{\"secondary_y\": True}, {\"secondary_y\": False}]],\n",
        "    vertical_spacing=0.12,\n",
        "    horizontal_spacing=0.1\n",
        ")\n",
        "\n",
        "# Convert Year_Month to string for plotting\n",
        "monthly_stats['Month_Str'] = monthly_stats['Year_Month'].astype(str)\n",
        "\n",
        "# Plot 1: Claim Frequency Trend with Volume\n",
        "fig3.add_trace(\n",
        "    go.Scatter(x=monthly_stats['Month_Str'], y=monthly_stats['Claim_Frequency'],\n",
        "               mode='lines+markers', name='Claim Frequency (%)',\n",
        "               line=dict(color='red', width=3)),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig3.add_trace(\n",
        "    go.Bar(x=monthly_stats['Month_Str'], y=monthly_stats['TotalPremium_count'],\n",
        "           name='Policy Count', opacity=0.6, marker_color='lightblue'),\n",
        "    row=1, col=1, secondary_y=True\n",
        ")\n",
        "\n",
        "# Plot 2: Loss Ratio Evolution\n",
        "fig3.add_trace(\n",
        "    go.Scatter(x=monthly_stats['Month_Str'], y=monthly_stats['Loss_Ratio'],\n",
        "               mode='lines+markers', name='Loss Ratio',\n",
        "               line=dict(color='orange', width=3), fill='tonexty'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Plot 3: Premium vs Claims Volume\n",
        "fig3.add_trace(\n",
        "    go.Scatter(x=monthly_stats['Month_Str'], y=monthly_stats['TotalPremium_sum'],\n",
        "               mode='lines+markers', name='Premium Volume',\n",
        "               line=dict(color='green', width=2)),\n",
        "    row=2, col=1\n",
        ")\n",
        "fig3.add_trace(\n",
        "    go.Scatter(x=monthly_stats['Month_Str'], y=monthly_stats['TotalClaims_sum'],\n",
        "               mode='lines+markers', name='Claims Volume',\n",
        "               line=dict(color='red', width=2)),\n",
        "    row=2, col=1, secondary_y=True\n",
        ")\n",
        "\n",
        "# Plot 4: Risk Score by Vehicle Age\n",
        "age_risk = df.groupby('VehicleAge').agg({\n",
        "    'HasClaim': 'mean',\n",
        "    'TotalClaims': 'mean'\n",
        "}).reset_index()\n",
        "age_risk['Risk_Score'] = age_risk['HasClaim'] * age_risk['TotalClaims']\n",
        "\n",
        "fig3.add_trace(\n",
        "    go.Bar(x=age_risk['VehicleAge'], y=age_risk['Risk_Score'],\n",
        "           name='Risk Score', marker_color='purple'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig3.update_layout(\n",
        "    title_text=\"üìä Insurance Analytics Dashboard: Temporal & Risk Evolution\",\n",
        "    title_x=0.5,\n",
        "    title_font_size=18,\n",
        "    height=800,\n",
        "    width=1200,\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Update y-axis labels\n",
        "fig3.update_yaxes(title_text=\"Claim Frequency (%)\", row=1, col=1)\n",
        "fig3.update_yaxes(title_text=\"Policy Count\", row=1, col=1, secondary_y=True)\n",
        "fig3.update_yaxes(title_text=\"Loss Ratio\", row=1, col=2)\n",
        "fig3.update_yaxes(title_text=\"Premium Volume ($)\", row=2, col=1)\n",
        "fig3.update_yaxes(title_text=\"Claims Volume ($)\", row=2, col=1, secondary_y=True)\n",
        "fig3.update_yaxes(title_text=\"Risk Score\", row=2, col=2)\n",
        "\n",
        "# Update x-axis labels\n",
        "fig3.update_xaxes(title_text=\"Month\", row=2, col=1)\n",
        "fig3.update_xaxes(title_text=\"Month\", row=2, col=2)\n",
        "fig3.update_xaxes(title_text=\"Vehicle Age (Years)\", row=2, col=2)\n",
        "\n",
        "fig3.show()\n",
        "print(\"‚úÖ Dashboard created - Comprehensive view of temporal trends and risk factors\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìã Key Findings & Business Insights\n",
        "\n",
        "### üéØ Summary of Findings:\n",
        "\n",
        "1. **Loss Ratio Analysis**\n",
        "   - Overall portfolio loss ratio indicates profitability health\n",
        "   - Significant variations exist across provinces and vehicle types\n",
        "   - Gender-based differences reveal pricing optimization opportunities\n",
        "\n",
        "2. **Financial Variables Distribution**\n",
        "   - Non-normal distributions in claims data suggest exponential/gamma models for pricing\n",
        "   - Outliers present in high-value claims requiring special handling\n",
        "   - Premium distributions show good spread across risk segments\n",
        "\n",
        "3. **Temporal Trends**\n",
        "   - Seasonal patterns in claim frequency and severity\n",
        "   - Monthly variations provide insights for cash flow planning\n",
        "   - Trend analysis reveals portfolio evolution over 18-month period\n",
        "\n",
        "4. **Vehicle Risk Factors**\n",
        "   - Clear risk differentiation by vehicle make and type\n",
        "   - Vehicle age correlation with claim patterns\n",
        "   - High-value vehicles show different risk profiles\n",
        "\n",
        "### üí° Business Recommendations:\n",
        "\n",
        "1. **Pricing Strategy**: Adjust premiums based on identified high-risk segments\n",
        "2. **Portfolio Management**: Monitor concentration in high-loss-ratio segments\n",
        "3. **Risk Assessment**: Incorporate vehicle age and type in risk scoring\n",
        "4. **Seasonal Planning**: Prepare for identified seasonal claim patterns\n",
        "\n",
        "### üìä Statistical Validation:\n",
        "- All analyses use appropriate statistical tests for significance\n",
        "- Confidence intervals calculated for key metrics\n",
        "- Correlation analysis validates relationships between variables\n",
        "\n",
        "---\n",
        "\n",
        "*Next Steps: Feature Engineering and Predictive Modeling*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
